# ADVERSARIAL NEURAL AUDIO SYNTHESIS

## ABSTRACT
**link :** https://arxiv.org/abs/1902.08710  
効率的な音声生成は機械学習のタスクの中で難しい部類である。  
WaveNetのような自己回帰モデルで音声生成はできるが、1回1回のサンプル生成に時間がかかり、その都度評価もしなければならないので生成が遅い。  
対照的に、Generative Adversarial Network(GAN)は効率的に音声を生成できるが、綺麗な音にするのが難しい。  
十分な条件下で行えばGANでもうまくいきます。  
この研究では、NSynthデータセットに対して実証実験をしてみてGANを使ってWaveNetのような自己回帰モデルでの生成よりもめっちゃ早く効率的に音声を生成できることを実証する。  

## 1 INTRODUCTION
生成のクオリティと汎用性の両方を効率的に達成するにはオーディオを生成するための生成モデルをトレーニングすることは難しい課題です。  
WaveNetなどの自己回帰モデルで汎化問題は解決されたが、1度に1オーディオしか生成できず、新規のオーディオは過去に生成されたオーディオに依存するため、生成速度が遅いのが問題でした。  
なので、たくさんの人が高速化に取り組んできましたが、これらの方法はかなりの確率でオーバーフィットをもたらしていました。  
また、敵対的学習であるGANが画像生成において高いクオリティを出しています。  
実際に、スペクトログラムとGANによる音声認識などの他のタスクではいくつか成功例があります。  
しかし、オーディオをスペクトルなどに画像化して、画像生成用のGANを用いてオーディオを生成しようとすると、画像ほどのクオリティはなかなか出せません。  

### 1.1 GENERATING INSTRUMENT TIMBRES
GANの研究者は、まず自由度が少ないデータセットでモデルを評価し、徐々に自由度が高いデータセットにしていくことで画像生成のモデリングの進歩を遂げた。  
例えば、ClebAデータセットは中央揃え、及びトリミングされた顔に制限され、姿勢とポーズによる違いをなくすことにより自由度を抑えている。  
その後、そのデータセットにより作られたモデルからより自由度の高いデータセットを用いて一般化しています。  
NSynthデータセットは、全てのタイプのオーディオを含むのではなく、ピッチ、音色、楽器などをそれぞれ細かく取り出した305,979もの数のデータからなるデータセットです。  
CelebAのように全てのデータが自由度が低くなるように調整されているデータでオーディオに関する細かいスケールで焦点が当てられるデータセットになっています。  

### 1.2 EFECTIVE AUDIO REPRESENTATIONS FOR GANS
画像とは違い、オーディオを周期性が高いという特徴を持っています。  
生成モデルの訓練は、人間の聴覚の範囲内の周波数ですることを条件としています。  
また、人間の知覚は周期的な波形の中の不連続性や不規則性に非常に敏感なので、短いデータからちょっと長いデータ(1ms ~ 100ms)に渡って周期的な規則性を維持することが重要です。  

### 1.3 CONTRIBUTIONS
この論文では、GANを使用してオーディオを合成する際のアーキテクチャを調べました。  
結果は以下の通りです：  
- 対数振幅と位相のスペクトログラムをGANで直接生成すると、従来の方法よりも一貫性のある波形を生成できる。
- IFスペクトルを推定すると、位相を直接推定するよりもよりコヒーレントなオーディオが得られる。  
- 高調波（倍音）を重ならないようにすることが重要ですが、低周波は狭い範囲に存在しているので重なりやすい。短時間フーリエ変換（STFT）のフレームサイズを大きくすることとMel周波数スケールに切り替えることによりこれを防げる。
- NSynthデータセットでは、GANはWaveNetの54,000倍の速さでサンプルを生成することができる。
- 潜在空間及びピッチ空間におけるグローバルな条件付けにより、滑らかで自然な音を生成できる。  

## 2 EXPERIMENTAL DETAILS
### 2.1 DATASET
ここではNSynthデータセットに焦点を合わせている。  
前述した通り、このデータセットは約300,000のオーディオデータから成ります。  
NSynthデータセットは多様な種類のデータがありますが、ラベルが細かく付けられています。  
各サンプルは4秒であり、16kHzで64,000次元に調整されています。  
この論文では人間による評価を行うために、アコースティック楽器かつMIDI24 - 84(~32 - 1000Hz)に限定しています。  
この選定により、弦楽器、金管楽器、木管楽器による70,379のデータが残りました。  

### 2.2 ARCHITECTURE AND REPRESENTATIONS
画像生成GANを元にして、オーディオをスペクトログラムに変換して、そのGANをそのまま使うやり方を考えた人がいました。パラメータ調整などかなり試行錯誤しています。  
ランダムベクトルzをサンプリングし、転置畳み込みの層を介し、出力データx = G(z)を生成する仕組みです。  
この方法とは異なり、この論文の方法は、音程や音色の独立した制御を達成するという音楽的にクオリティを上げています。  
ジェネレータが音に関する情報を多様に扱うために、ピッチラベルを予測しようとする弁別器に補助的な損失も追加する。  

