# ADVERSARIAL NEURAL AUDIO SYNTHESIS

## ABSTRACT
**link :** https://arxiv.org/abs/1902.08710  
効率的な音声生成は機械学習のタスクの中で難しい部類である。  
WaveNetのような自己回帰モデルで音声生成はできるが、1回1回のサンプル生成に時間がかかり、その都度評価もしなければならないので生成が遅い。  
対照的に、Generative Adversarial Network(GAN)は効率的に音声を生成できるが、綺麗な音にするのが難しい。  
十分な条件下で行えばGANでもうまくいきます。  
この研究では、NSynthデータセットに対して実証実験をしてみてGANを使ってWaveNetのような自己回帰モデルでの生成よりもめっちゃ早く効率的に音声を生成できることを実証する。  

## 1 INTRODUCTION
生成のクオリティと汎用性の両方を効率的に達成するにはオーディオを生成するための生成モデルをトレーニングすることは難しい課題です。  
WaveNetなどの自己回帰モデルで汎化問題は解決されたが、1度に1オーディオしか生成できず、新規のオーディオは過去に生成されたオーディオに依存するため、生成速度が遅いのが問題でした。  
なので、たくさんの人が高速化に取り組んできましたが、これらの方法はかなりの確率でオーバーフィットをもたらしていました。  
また、敵対的学習であるGANが画像生成において高いクオリティを出しています。  
実際に、スペクトログラムとGANによる音声認識などの他のタスクではいくつか成功例があります。  
しかし、オーディオをスペクトルなどに画像化して、画像生成用のGANを用いてオーディオを生成しようとすると、画像ほどのクオリティはなかなか出せません。  

### 1.1 GENERATING INSTRUMENT TIMBRES
GANの研究者は、まず自由度が少ないデータセットでモデルを評価し、徐々に自由度が高いデータセットにしていくことで画像生成のモデリングの進歩を遂げた。  
例えば、ClebAデータセットは中央揃え、及びトリミングされた顔に制限され、姿勢とポーズによる違いをなくすことにより自由度を抑えている。  
その後、そのデータセットにより作られたモデルからより自由度の高いデータセットを用いて一般化しています。  
NSynthデータセットは、全てのタイプのオーディオを含むのではなく、ピッチ、音色、楽器などをそれぞれ細かく取り出した305,979もの数のデータからなるデータセットです。  
CelebAのように全てのデータが自由度が低くなるように調整されているデータでオーディオに関する細かいスケールで焦点が当てられるデータセットになっています。  

### 1.2 EFECTIVE AUDIO REPRESENTATIONS FOR GANS
画像とは違い、オーディオを周期性が高いという特徴を持っています。  
生成モデルの訓練は、人間の聴覚の範囲内の周波数ですることを条件としています。  
また、人間の知覚は周期的な波形の中の不連続性や不規則性に非常に敏感なので、短いデータからちょっと長いデータ(1ms ~ 100ms)に渡って周期的な規則性を維持することが重要です。  

### 1.3 CONTRIBUTIONS
この論文では、GANを使用してオーディオを合成する際のアーキテクチャを調べました。  
結果は以下の通りです：  
- 対数振幅と位相のスペクトログラムをGANで直接生成すると、従来の方法よりも一貫性のある波形を生成できる。
- IFスペクトルを推定すると、位相を直接推定するよりもよりコヒーレントなオーディオが得られる。  
- 高調波（倍音）を重ならないようにすることが重要ですが、低周波は狭い範囲に存在しているので重なりやすい。短時間フーリエ変換（STFT）のフレームサイズを大きくすることとMel周波数スケールに切り替えることによりこれを防げる。
- NSynthデータセットでは、GANはWaveNetの54,000倍の速さでサンプルを生成することができる。
- 潜在空間及びピッチ空間におけるグローバルな条件付けにより、滑らかで自然な音を生成できる。  

## 2 EXPERIMENTAL DETAILS
### 2.1 DATASET
ここではNSynthデータセットに焦点を合わせている。  
前述した通り、このデータセットは約300,000のオーディオデータから成ります。  
NSynthデータセットは多様な種類のデータがありますが、ラベルが細かく付けられています。  
各サンプルは4秒であり、16kHzで64,000次元に調整されています。  
この論文では人間による評価を行うために、アコースティック楽器かつMIDI24 - 84(~32 - 1000Hz)に限定しています。  
この選定により、弦楽器、金管楽器、木管楽器による70,379のデータが残りました。  

### 2.2 ARCHITECTURE AND REPRESENTATIONS
画像生成GANを元にして、オーディオをスペクトログラムに変換して、そのGANをそのまま使うやり方を考えた人がいました。パラメータ調整などかなり試行錯誤しています。  
ランダムベクトルzをサンプリングし、転置畳み込みの層を介し、出力データx = G(z)を生成する仕組みです。  
この方法とは異なり、この論文の方法は、音程や音色の独立した制御を達成するという音楽的にクオリティを上げています。  
ジェネレータが音に関する情報を多様に扱うために、ピッチラベルを予測しようとする弁別器に補助的な損失も追加する。  

## 3 METRICS
生成モデルの評価は難しい課題です。この論文では、全てのモデルを様々な評価手法を用いて評価しています。  
評価手法は次の通りです。  

- **人間による評価**

定量的評価で全てを決めるのが難しいため、人間の評価を中心として添えています。  
特に、人間の近くは位相の不規則性に非常に敏感であり、生成されたオーディオに不規則性が生じている場合気付きやすい。  
なので、この論文の目指すコヒーレントなオーディオかどうかの評価につながります。  
評価者には、同じピッチに対応する4秒のサンプルが2つ提示されます。  
5段階評価でサンプルAはサンプルBよりも音質が良い/音の歪みが少ない・・・などの基準で評価します。  
これらの評価を合計3600件集め、モデル単位で800件集めています。  

- **統計的に異なるビンの数(NDB)**

これはRichardson&Weiss(2018)によって提案された手法です。  
生成されたモデルの多様性を測定するために使用しています。  
トレーニング用データを対数スペクトログラム空間においてk-means法を用いてk = 50Voronoi cellsにクラスター化し、生成されたオーディオも同様にマッピングし、近いセルに割り当てます。  

- **Inception Score(IS)**

Inception Scoreは、生成されたものが識別しやすいほどまたは生成されるものの種類が豊富であるほど高くなります。  

以下の式に示すカルバック・ライブラー情報量を各データについて求めます。

<img src="https://latex.codecogs.com/gif.latex?D_{KL}&space;(P(y|x_i)&space;||&space;P(y))&space;=&space;\sum_{y&space;\in&space;Y}&space;P(y|x_i)&space;log&space;\frac{P(y|x_i)}{P(y)}" />

その後、このカルバック・ライブラー情報量の平均を取り、expを取るとInception Scoreになります。

<img src="https://latex.codecogs.com/gif.latex?\exp&space;\left(&space;\frac{1}{|X|}&space;\sum_{x_i&space;\in&space;X}&space;D_{KL}&space;(P(y|x_i)&space;||&space;P(y))&space;\right)" />

- **ピッチ精度(PA)及びピッチエントロピー**

Inception Scoreは明確なピッチを生成しないモデルと一定のピッチのみしか生成しないモデルを判別できないため、生成されたオーディオのピッチの精度(PA)と出力分布のエントロピー(PE)を測っています。  

- **フレッシュ開始距離(FID)**  

Inception分類器から抽出された特徴に適合する多変量ガウス分布間を2-Wasserstain距離を用いて測ります。  
Inception Scoreと同様にInception機能の代わりにピッチ分類機能を使用しています。  
